{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm,metrics\n",
    "# from sklearn.neighbors import KNeighborsClassifier  #분류\n",
    "# from sklearn.neighbors import KNeighborsRegressor  #예측\n",
    "from sklearn.linear_model import LinearRegression  #선형회귀\n",
    "from sklearn.preprocessing import PolynomialFeatures  #다항특성을 만들어주는 라이브러리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "matplotlib.rcParams['font.family']='Malgun Gothic'  #한글설정\n",
    "matplotlib.rcParams['font.size']= '10'  #글자크기\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0,\n",
    "33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]\n",
    "bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0,\n",
    "610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]\n",
    "#[ 빙어 ]\n",
    "smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]\n",
    "smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=bream_length+smelt_length\n",
    "weight=bream_weight+smelt_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25.4, 242.0],\n",
       " [26.3, 290.0],\n",
       " [26.5, 340.0],\n",
       " [29.0, 363.0],\n",
       " [29.0, 430.0],\n",
       " [29.7, 450.0],\n",
       " [29.7, 500.0],\n",
       " [30.0, 390.0],\n",
       " [30.0, 450.0],\n",
       " [30.7, 500.0],\n",
       " [31.0, 475.0],\n",
       " [31.0, 500.0],\n",
       " [31.5, 500.0],\n",
       " [32.0, 340.0],\n",
       " [32.0, 600.0],\n",
       " [32.0, 600.0],\n",
       " [33.0, 700.0],\n",
       " [33.0, 700.0],\n",
       " [33.5, 610.0],\n",
       " [33.5, 650.0],\n",
       " [34.0, 575.0],\n",
       " [34.0, 685.0],\n",
       " [34.5, 620.0],\n",
       " [35.0, 680.0],\n",
       " [35.0, 700.0],\n",
       " [35.0, 725.0],\n",
       " [35.0, 720.0],\n",
       " [36.0, 714.0],\n",
       " [36.0, 850.0],\n",
       " [37.0, 1000.0],\n",
       " [38.5, 920.0],\n",
       " [38.5, 955.0],\n",
       " [39.5, 925.0],\n",
       " [41.0, 975.0],\n",
       " [41.0, 950.0],\n",
       " [9.8, 6.7],\n",
       " [10.5, 7.5],\n",
       " [10.6, 7.0],\n",
       " [11.0, 9.7],\n",
       " [11.2, 9.8],\n",
       " [11.3, 8.7],\n",
       " [11.8, 10.0],\n",
       " [11.8, 9.9],\n",
       " [12.0, 9.8],\n",
       " [12.2, 12.2],\n",
       " [12.4, 13.4],\n",
       " [13.0, 12.2],\n",
       " [14.3, 19.7],\n",
       " [15.0, 19.9]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas=[[l,w] for l,w in zip(length,weight)]\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로지스틱 회귀를 적용해서 도미,빙어 test 세트 5개 분류하고\n",
    "\n",
    "# 5개를 몇%의 확률로 선택했는지 출력하시오.\n",
    "\n",
    "#train,test 정답률을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.to_numpy of 0     도미\n",
       "1     도미\n",
       "2     도미\n",
       "3     도미\n",
       "4     도미\n",
       "5     도미\n",
       "6     도미\n",
       "7     도미\n",
       "8     도미\n",
       "9     도미\n",
       "10    도미\n",
       "11    도미\n",
       "12    도미\n",
       "13    도미\n",
       "14    도미\n",
       "15    도미\n",
       "16    도미\n",
       "17    도미\n",
       "18    도미\n",
       "19    도미\n",
       "20    도미\n",
       "21    도미\n",
       "22    도미\n",
       "23    도미\n",
       "24    도미\n",
       "25    도미\n",
       "26    도미\n",
       "27    도미\n",
       "28    도미\n",
       "29    도미\n",
       "30    도미\n",
       "31    도미\n",
       "32    도미\n",
       "33    도미\n",
       "34    도미\n",
       "35    빙어\n",
       "36    빙어\n",
       "37    빙어\n",
       "38    빙어\n",
       "39    빙어\n",
       "40    빙어\n",
       "41    빙어\n",
       "42    빙어\n",
       "43    빙어\n",
       "44    빙어\n",
       "45    빙어\n",
       "46    빙어\n",
       "47    빙어\n",
       "48    빙어\n",
       "Name: 2, dtype: object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_length=np.array(bream_length+smelt_length)\n",
    "a_weight=np.array(bream_weight+smelt_weight)\n",
    "a_target=np.array(['도미']*35+['빙어']*14)\n",
    "df=pd.DataFrame([a_length,a_weight,a_target])\n",
    "df=df.T\n",
    "df\n",
    "target=df[2].to_numpy\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  25.4,  242. ],\n",
       "       [  26.3,  290. ],\n",
       "       [  26.5,  340. ],\n",
       "       [  29. ,  363. ],\n",
       "       [  29. ,  430. ],\n",
       "       [  29.7,  450. ],\n",
       "       [  29.7,  500. ],\n",
       "       [  30. ,  390. ],\n",
       "       [  30. ,  450. ],\n",
       "       [  30.7,  500. ],\n",
       "       [  31. ,  475. ],\n",
       "       [  31. ,  500. ],\n",
       "       [  31.5,  500. ],\n",
       "       [  32. ,  340. ],\n",
       "       [  32. ,  600. ],\n",
       "       [  32. ,  600. ],\n",
       "       [  33. ,  700. ],\n",
       "       [  33. ,  700. ],\n",
       "       [  33.5,  610. ],\n",
       "       [  33.5,  650. ],\n",
       "       [  34. ,  575. ],\n",
       "       [  34. ,  685. ],\n",
       "       [  34.5,  620. ],\n",
       "       [  35. ,  680. ],\n",
       "       [  35. ,  700. ],\n",
       "       [  35. ,  725. ],\n",
       "       [  35. ,  720. ],\n",
       "       [  36. ,  714. ],\n",
       "       [  36. ,  850. ],\n",
       "       [  37. , 1000. ],\n",
       "       [  38.5,  920. ],\n",
       "       [  38.5,  955. ],\n",
       "       [  39.5,  925. ],\n",
       "       [  41. ,  975. ],\n",
       "       [  41. ,  950. ],\n",
       "       [   9.8,    6.7],\n",
       "       [  10.5,    7.5],\n",
       "       [  10.6,    7. ],\n",
       "       [  11. ,    9.7],\n",
       "       [  11.2,    9.8],\n",
       "       [  11.3,    8.7],\n",
       "       [  11.8,   10. ],\n",
       "       [  11.8,    9.9],\n",
       "       [  12. ,    9.8],\n",
       "       [  12.2,   12.2],\n",
       "       [  12.4,   13.4],\n",
       "       [  13. ,   12.2],\n",
       "       [  14.3,   19.7],\n",
       "       [  15. ,   19.9]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_length=np.array(bream_length+smelt_length)\n",
    "a_weight=np.array(bream_weight+smelt_weight)\n",
    "a_target=np.array(['도미']*35+['빙어']*14)\n",
    "data=np.column_stack((length,weight))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input,test_input,train_target,test_target=train_test_split(\n",
    "    length,weight,random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[30.  29.  29.7 11.3 11.8 13.  32.  30.7 33.  35.  41.  38.5 25.4 12.\n 39.5 29.7 37.  31.  10.5 26.3 34.  26.5 10.6  9.8 35.  11.2 31.  34.5\n 33.5 15.  34.  30.  11.8 32.  36.  11. ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      2\u001b[0m ss\u001b[38;5;241m=\u001b[39mStandardScaler()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m train_scaled \u001b[38;5;241m=\u001b[39mss\u001b[38;5;241m.\u001b[39mtransform(train_input)\n\u001b[0;32m      5\u001b[0m test_scaled \u001b[38;5;241m=\u001b[39mss\u001b[38;5;241m.\u001b[39mtransform(test_input)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:876\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:912\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    911\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1035\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1029\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1030\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1032\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1033\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1034\u001b[0m             )\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[30.  29.  29.7 11.3 11.8 13.  32.  30.7 33.  35.  41.  38.5 25.4 12.\n 39.5 29.7 37.  31.  10.5 26.3 34.  26.5 10.6  9.8 35.  11.2 31.  34.5\n 33.5 15.  34.  30.  11.8 32.  36.  11. ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled =ss.transform(train_input)\n",
    "test_scaled =ss.transform(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#max_iter : 반복횟수 =100 기본설정\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# C 규제: 올라가면 규제 약해지고 낮아지면 강해짐. 선형회귀 규제=alpha값으로 지정\u001b[39;00m\n\u001b[0;32m      4\u001b[0m lr\u001b[38;5;241m=\u001b[39mLogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_scaled\u001b[49m, train_target)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#max_iter : 반복횟수 =100 기본설정\n",
    "# C 규제: 올라가면 규제 약해지고 낮아지면 강해짐. 선형회귀 규제=alpha값으로 지정\n",
    "lr=LogisticRegression(C=20, max_iter=1000)\n",
    "lr.fit(train_scaled, train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict=lr.predict(test_scaled[:5])\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.score(train_scaled,train_target))\n",
    "print(lr.score(test_scaled,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(test_scaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba=lr.predict_proba(test_scaled[:5])\n",
    "print(np.decimals=2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
