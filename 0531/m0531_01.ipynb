{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family']='Malgun Gothic'  #한글설정\n",
    "matplotlib.rcParams['font.size']= 10  #글자크기\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imdb 데이터 불러오기\n",
    "#단어사전은 500개까지 만 가져옴\n",
    "#원핫인코딩하면 500개 컬럼이 만들어짐.\n",
    "(train_input,train_target),(test_input,test_target)=keras.datasets.imdb.load_data(\n",
    "    num_words = 500 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape,test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "#1의 의미:토큰시작\n",
    "#2의 의미: 단어사전에 없는 단어\n",
    "print(train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#2진 분류binary: 긍정 -1 , 부정- 0 \n",
    "print(train_target[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_input,val_input,train_target,val_target = train_test_split(\n",
    "    train_input,train_target,test_size=0.2,random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape,val_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([259, 520, 290, ..., 300,  70,  77])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths=np.array([len(x) for x in train_input])\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1854"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths)\n",
    "plt.xlabel('길이')\n",
    "plt.ylabel('개수')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시퀀스 패딩\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_seq = pad_sequences(train_input,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
      "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
      "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
      "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
      "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
      "   6   2  46   7  14  20  10  10 470 158]\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스패딩 적용해서 0이 없으면 글자 짤린것임.\n",
    "# 시퀀스 패딩은 100개이상의 글자를 짜를때 앞부분을 짜름.(뒤 내용이 더 중요판단)\n",
    "print(train_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
      "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
      "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
      "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
      "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
      "   2   2 290   2  46  48  64  18   4   2]\n"
     ]
    }
   ],
   "source": [
    "#6번째 샘플 앞부분 0으로 채워져 있음\n",
    "#100개 단어보다 적은 데이터 임.\n",
    "print(train_seq[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32,   2, 225, ...,  14,  58,   2],\n",
       "       [ 53,   2,   8, ...,   7,  32,   2],\n",
       "       [  0,   0,   0, ...,   2,  33,  32],\n",
       "       ...,\n",
       "       [383,   2, 120, ...,  16,  99,  76],\n",
       "       [106, 345,  12, ..., 120,   2, 156],\n",
       "       [  4, 114,  21, ...,   4,   2,   2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#검증세트\n",
    "val_seq=pad_sequences(val_input,maxlen=100)\n",
    "val_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#순환신경망 모델 구현\n",
    "model=keras.Sequential()\n",
    "#순환신경망(RNN) 알고리즘\n",
    "\n",
    "#시퀀스패딩- 크기100, 단어사전-500개\n",
    "model.add(keras.layers.SimpleRNN(8,input_shape=(100,500)))\n",
    "#이진분류\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,   4,  20,   9,   2, 364, 352,   5,  45,   6,   2,   2,  33,\n",
       "       269,   8,   2, 142,   2,   5,   2,  17,  73,  17, 204,   5,   2,\n",
       "        19,  55,   2,   2,  92,  66, 104,  14,  20,  93,  76,   2, 151,\n",
       "        33,   4,  58,  12, 188,   2, 151,  12, 215,  69, 224, 142,  73,\n",
       "       237,   6,   2,   7,   2,   2, 188,   2, 103,  14,  31,  10,  10,\n",
       "       451,   7,   2,   5,   2,  80,  91,   2,  30,   2,  34,  14,  20,\n",
       "       151,  50,  26, 131,  49,   2,  84,  46,  50,  37,  80,  79,   6,\n",
       "         2,  46,   7,  14,  20,  10,  10, 470, 158])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit훈련 데이터 3차원 행렬\n",
    "train_seq[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh=keras.utils.to_categorical(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,   4,  20,   9,   2, 364, 352,   5,  45,   6,   2,   2,  33,\n",
       "       269,   8,   2, 142,   2,   5,   2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩 된 값 출력 - 10번째 값이 1로 변경\n",
    "train_oh[0][0][:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 500개 컬럼의 합은 무조건 1 - 원핫인코딩\n",
    "print(np.sum(train_oh[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_seq 원핫인코딩\n",
    "val_oh = keras.utils.to_categorical(val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m4,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,081</span> (15.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,081\u001b[0m (15.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,081</span> (15.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,081\u001b[0m (15.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5001 - loss: 0.6989 - val_accuracy: 0.4996 - val_loss: 0.6971\n",
      "Epoch 2/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5081 - loss: 0.6942 - val_accuracy: 0.5036 - val_loss: 0.6953\n",
      "Epoch 3/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5198 - loss: 0.6915 - val_accuracy: 0.5070 - val_loss: 0.6940\n",
      "Epoch 4/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5307 - loss: 0.6901 - val_accuracy: 0.5150 - val_loss: 0.6928\n",
      "Epoch 5/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5365 - loss: 0.6894 - val_accuracy: 0.5194 - val_loss: 0.6920\n",
      "Epoch 6/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5420 - loss: 0.6878 - val_accuracy: 0.5234 - val_loss: 0.6910\n",
      "Epoch 7/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5475 - loss: 0.6857 - val_accuracy: 0.5294 - val_loss: 0.6902\n",
      "Epoch 8/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5507 - loss: 0.6854 - val_accuracy: 0.5352 - val_loss: 0.6892\n",
      "Epoch 9/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5679 - loss: 0.6822 - val_accuracy: 0.5390 - val_loss: 0.6885\n",
      "Epoch 10/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5644 - loss: 0.6820 - val_accuracy: 0.5426 - val_loss: 0.6876\n",
      "Epoch 11/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5727 - loss: 0.6800 - val_accuracy: 0.5446 - val_loss: 0.6866\n",
      "Epoch 12/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5771 - loss: 0.6788 - val_accuracy: 0.5452 - val_loss: 0.6857\n",
      "Epoch 13/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5848 - loss: 0.6764 - val_accuracy: 0.5466 - val_loss: 0.6847\n",
      "Epoch 14/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5895 - loss: 0.6741 - val_accuracy: 0.5494 - val_loss: 0.6840\n",
      "Epoch 15/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5937 - loss: 0.6725 - val_accuracy: 0.5504 - val_loss: 0.6829\n",
      "Epoch 16/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5984 - loss: 0.6704 - val_accuracy: 0.5542 - val_loss: 0.6819\n",
      "Epoch 17/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6039 - loss: 0.6675 - val_accuracy: 0.5574 - val_loss: 0.6803\n",
      "Epoch 18/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6044 - loss: 0.6655 - val_accuracy: 0.5630 - val_loss: 0.6789\n",
      "Epoch 19/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6126 - loss: 0.6625 - val_accuracy: 0.5660 - val_loss: 0.6769\n",
      "Epoch 20/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6193 - loss: 0.6586 - val_accuracy: 0.5698 - val_loss: 0.6746\n",
      "Epoch 21/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6242 - loss: 0.6553 - val_accuracy: 0.5778 - val_loss: 0.6711\n",
      "Epoch 22/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6310 - loss: 0.6504 - val_accuracy: 0.5832 - val_loss: 0.6673\n",
      "Epoch 23/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6419 - loss: 0.6466 - val_accuracy: 0.5930 - val_loss: 0.6633\n",
      "Epoch 24/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6457 - loss: 0.6402 - val_accuracy: 0.6066 - val_loss: 0.6571\n",
      "Epoch 25/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6573 - loss: 0.6346 - val_accuracy: 0.6130 - val_loss: 0.6528\n",
      "Epoch 26/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6671 - loss: 0.6285 - val_accuracy: 0.6236 - val_loss: 0.6473\n",
      "Epoch 27/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6694 - loss: 0.6250 - val_accuracy: 0.6358 - val_loss: 0.6405\n",
      "Epoch 28/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6782 - loss: 0.6173 - val_accuracy: 0.6450 - val_loss: 0.6352\n",
      "Epoch 29/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6816 - loss: 0.6108 - val_accuracy: 0.6480 - val_loss: 0.6315\n",
      "Epoch 30/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6859 - loss: 0.6058 - val_accuracy: 0.6538 - val_loss: 0.6281\n",
      "Epoch 31/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6915 - loss: 0.5984 - val_accuracy: 0.6550 - val_loss: 0.6250\n",
      "Epoch 32/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6905 - loss: 0.5968 - val_accuracy: 0.6540 - val_loss: 0.6242\n",
      "Epoch 33/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6998 - loss: 0.5899 - val_accuracy: 0.6562 - val_loss: 0.6199\n",
      "Epoch 34/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7043 - loss: 0.5851 - val_accuracy: 0.6582 - val_loss: 0.6166\n",
      "Epoch 35/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7038 - loss: 0.5843 - val_accuracy: 0.6640 - val_loss: 0.6143\n",
      "Epoch 36/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7113 - loss: 0.5752 - val_accuracy: 0.6570 - val_loss: 0.6151\n",
      "Epoch 37/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7036 - loss: 0.5786 - val_accuracy: 0.6632 - val_loss: 0.6149\n",
      "Epoch 38/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7124 - loss: 0.5708 - val_accuracy: 0.6646 - val_loss: 0.6100\n",
      "Epoch 39/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7180 - loss: 0.5663 - val_accuracy: 0.6678 - val_loss: 0.6097\n",
      "Epoch 40/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7160 - loss: 0.5647 - val_accuracy: 0.6670 - val_loss: 0.6087\n",
      "Epoch 41/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7197 - loss: 0.5585 - val_accuracy: 0.6666 - val_loss: 0.6084\n",
      "Epoch 42/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7216 - loss: 0.5575 - val_accuracy: 0.6676 - val_loss: 0.6056\n",
      "Epoch 43/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.5609 - val_accuracy: 0.6682 - val_loss: 0.6052\n",
      "Epoch 44/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7205 - loss: 0.5555 - val_accuracy: 0.6714 - val_loss: 0.6055\n",
      "Epoch 45/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7256 - loss: 0.5503 - val_accuracy: 0.6708 - val_loss: 0.6039\n",
      "Epoch 46/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7287 - loss: 0.5493 - val_accuracy: 0.6736 - val_loss: 0.6037\n",
      "Epoch 47/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7346 - loss: 0.5434 - val_accuracy: 0.6724 - val_loss: 0.6028\n",
      "Epoch 48/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7236 - loss: 0.5511 - val_accuracy: 0.6730 - val_loss: 0.6027\n",
      "Epoch 49/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7369 - loss: 0.5406 - val_accuracy: 0.6744 - val_loss: 0.6055\n",
      "Epoch 50/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7383 - loss: 0.5373 - val_accuracy: 0.6766 - val_loss: 0.6020\n",
      "Epoch 51/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7332 - loss: 0.5388 - val_accuracy: 0.6750 - val_loss: 0.6039\n",
      "Epoch 52/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7343 - loss: 0.5415 - val_accuracy: 0.6760 - val_loss: 0.6015\n",
      "Epoch 53/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7365 - loss: 0.5362 - val_accuracy: 0.6768 - val_loss: 0.6031\n",
      "Epoch 54/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7357 - loss: 0.5338 - val_accuracy: 0.6778 - val_loss: 0.6020\n",
      "Epoch 55/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7408 - loss: 0.5342 - val_accuracy: 0.6746 - val_loss: 0.6043\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망 훈련 동일\n",
    "# Flatten 필요없음. 원핫인코딩\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer=rmsprop,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('simpleRnn_model.keras')\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True )\n",
    "history = model.fit(train_oh,train_target,batch_size=64,epochs=100,\n",
    "                     validation_data=(val_oh,val_target), \n",
    "                     callbacks=[checkpoint_cb,early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history,\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel()\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plt.plot(history,history['loss'])\n",
    "plt.xlabel()\n",
    "plt.ylabel\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop위치 출력\n",
    "early_stoppping_cb.stopped_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_seq = pad_sequences(test_input,maxlen=100)\n",
    "#원핫 인코딩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_4 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2=keras.Sequential()\n",
    "#임베딩층 추가\n",
    "model2.add(keras.layers.Embedding(500,16,input_length=100))\n",
    "model2.add(keras.layers.SimpleRNN(8))\n",
    "model2.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5089 - loss: 0.6937 - val_accuracy: 0.5454 - val_loss: 0.6885\n",
      "Epoch 2/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5898 - loss: 0.6801 - val_accuracy: 0.6350 - val_loss: 0.6663\n",
      "Epoch 3/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6551 - loss: 0.6576 - val_accuracy: 0.6764 - val_loss: 0.6459\n",
      "Epoch 4/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6946 - loss: 0.6340 - val_accuracy: 0.7134 - val_loss: 0.6257\n",
      "Epoch 5/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7272 - loss: 0.6127 - val_accuracy: 0.7292 - val_loss: 0.6036\n",
      "Epoch 6/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7381 - loss: 0.5938 - val_accuracy: 0.7306 - val_loss: 0.5880\n",
      "Epoch 7/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7501 - loss: 0.5713 - val_accuracy: 0.7494 - val_loss: 0.5643\n",
      "Epoch 8/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7614 - loss: 0.5482 - val_accuracy: 0.7608 - val_loss: 0.5414\n",
      "Epoch 9/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7758 - loss: 0.5256 - val_accuracy: 0.7696 - val_loss: 0.5255\n",
      "Epoch 10/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7738 - loss: 0.5130 - val_accuracy: 0.7694 - val_loss: 0.5144\n",
      "Epoch 11/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7850 - loss: 0.4961 - val_accuracy: 0.7744 - val_loss: 0.5058\n",
      "Epoch 12/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7862 - loss: 0.4873 - val_accuracy: 0.7556 - val_loss: 0.5189\n",
      "Epoch 13/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7878 - loss: 0.4825 - val_accuracy: 0.7458 - val_loss: 0.5265\n",
      "Epoch 14/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7988 - loss: 0.4685 - val_accuracy: 0.7656 - val_loss: 0.5037\n",
      "Epoch 15/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7985 - loss: 0.4637 - val_accuracy: 0.7796 - val_loss: 0.4810\n",
      "Epoch 16/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8020 - loss: 0.4582 - val_accuracy: 0.7622 - val_loss: 0.4973\n",
      "Epoch 17/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8071 - loss: 0.4506 - val_accuracy: 0.7826 - val_loss: 0.4746\n",
      "Epoch 18/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8065 - loss: 0.4461 - val_accuracy: 0.7764 - val_loss: 0.4820\n",
      "Epoch 19/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8059 - loss: 0.4471 - val_accuracy: 0.7800 - val_loss: 0.4746\n",
      "Epoch 20/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8088 - loss: 0.4382 - val_accuracy: 0.7662 - val_loss: 0.4951\n",
      "Epoch 21/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8086 - loss: 0.4361 - val_accuracy: 0.7730 - val_loss: 0.4811\n",
      "Epoch 22/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8204 - loss: 0.4235 - val_accuracy: 0.7852 - val_loss: 0.4671\n",
      "Epoch 23/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8180 - loss: 0.4259 - val_accuracy: 0.7806 - val_loss: 0.4717\n",
      "Epoch 24/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8173 - loss: 0.4215 - val_accuracy: 0.7578 - val_loss: 0.5162\n",
      "Epoch 25/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8148 - loss: 0.4257 - val_accuracy: 0.7824 - val_loss: 0.4644\n",
      "Epoch 26/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8223 - loss: 0.4185 - val_accuracy: 0.7860 - val_loss: 0.4666\n",
      "Epoch 27/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8170 - loss: 0.4201 - val_accuracy: 0.7756 - val_loss: 0.4753\n",
      "Epoch 28/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8245 - loss: 0.4114 - val_accuracy: 0.7770 - val_loss: 0.4755\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망 훈련 동일\n",
    "# Flatten 필요없음. 원핫인코딩을 사용하지 않음, embedding을 사용\n",
    "#train_oh ->train_seq 데이터 사용\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model2.compile(optimizer=rmsprop,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('simpleRnn_embedding_model.keras')\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True )\n",
    "history = model2.fit(train_seq,train_target,batch_size=64,epochs=100,\n",
    "                     validation_data=(val_seq,val_target), \n",
    "                     callbacks=[checkpoint_cb,early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7909 - loss: 0.4579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4582229554653168, 0.788919985294342]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq=pad_sequences(test_input,maxlen=100)\n",
    "model2.evaluate(test_seq,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 훈련\n",
    "# 데이터전처리 train_scaled = train_input.reshape(-1,28,28,1)/255\n",
    "# 모델결정 model = keras.Sequential()\n",
    "#model2.add(keras.layers.Embedding(500,16,input_length=100))\n",
    "\n",
    "\n",
    "# 인공신경망 훈련\n",
    "# Flatten 추가  model.add(keras.layers.Flatten())\n",
    "# Dense층 추가  model.add(keras.layers.Dense(100,activation='relu'))\n",
    "# 드롭아웃추가  model.add(keras.layers.Dropout(0.4)) # 40%를 제외시키는 규제적용\n",
    "# Dense층 추가  model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "# 모델설정 옵티마이저 - adam\n",
    "# model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# 콜백모델체크포인트 checkpoint_cb = keras.callbacks.ModelCheckpoint('best_model.keras')\n",
    "# 종기종료 early_stopping_cb = keras.callbacks.EarlyStopping(patience=2,restore_best_weights=True )\n",
    "# 모델훈련 history = model.fit(train_scaled,train_target,batch_size=32,epochs=20,\n",
    "#                      validation_data=(val_scaled,val_target), callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "# 모델평가 model.evaluate(val_scaled,val_targ\n",
    "\n",
    "#test세트 검증-3차원행렬로 변경해서 test진행해야 함.\n",
    "#시퀀스 패딩\n",
    "# test_seq = pad_sequences(test_input,maxlen=100)\n",
    "#원핫인코딩\n",
    "#train_oh=kera.utils.to_categorical(test_seq)\n",
    "#model.evaluate(train_oh,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 인공신경망 훈련 동일\n",
    "# # Flatten 필요없음. 원핫인코딩\n",
    "# rmsprop = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "# model.compile(optimizer=rmsprop,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint('simpleRnn_model.keras')\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True )\n",
    "# history = model.fit(train_oh,train_target,batch_size=64,epochs=100,\n",
    "#                      validation_data=(val_oh,val_target), \n",
    "#                      callbacks=[checkpoint_cb,early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
